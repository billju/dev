<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio</title>
</head>
<body>
    <input type="file" onchange="handleFile(event.target.files[0])">
    <div id="drop-field" ondrop="handleDrop(event)" ondragover="event.preventDefault()">drop here</div>
    <canvas id="waveform"></canvas>
    <canvas id="canvas"></canvas>
    <button onclick="player.play()">play</button>
    <div id="audio-control" style="width: 500px;height: 10px;background: #000;"></div>
</body>
<style>
    html,body{
        margin: 0;
    }
    #waveform{
        width: 100%;
        height: 50px;
    }
    #canvas{
        width: 500px;
        height: 200px;
    }
    #drop-field{
        width: 50px;
        height: 50px;
        border: 1px solid #000;
    }
</style>
<script>
class Visualizer{
    constructor(player){
        this.player = player
        this.analyser = player.aCtx.createAnalyser()
        player.source.connect(this.analyser)
        this.analyser.connect(player.gain)
    }
    getFormatTime(time, format="hh:mm:ss"){
        const cT = time||this.player.audio.currentTime
        const ss = ('0'+~~(cT%60)).substr(-2)
        const mm = ('0'+~~(cT/60)).substr(-2)
        const hh = ('0'+~~(cT/3600)).substr(-2)
        return format.replace('hh',hh).replace('mm',mm).replace('ss',ss)
    }
    createController(container){
        const bar = document.createElement('div')
        // const getFormatTime = this.getFormatTime
        container.innerHTML = ''
        container.appendChild(bar)
        const audio = this.player.audio
        bar.style.height = '100%'
        bar.style.background = '#eee'
        this.player.audio.addEventListener('time-update', ()=>{
            if(!bar.active){
                bar.style.width = container.clientWidth*audio.currentTime/audio.duration+'px'
                bar.innerText = this.getFormatTime()
            }
        })
        container.onmousedown = e=>{
            bar.active = true
        }
        container.onmousemove = e=>{
            if(bar.active){
                let pct = (e.clientX-container.offsetLeft)/container.clientWidth
                bar.style.width = pct*container.clientWidth+'px'
                bar.innerText = this.getFormatTime(pct*audio.duration)
            }
        }
        function handleEnd(e){
            if(bar.active){
                let pct = (e.clientX-container.offsetLeft)/container.clientWidth
                audio.currentTime = pct*audio.duration
                bar.active = false
            }
        }
        container.onmouseup = handleEnd
        container.onmouseleave = handleEnd
    }
    getPeaks(width, data){
        let step = Math.floor(data.length/width)
        let peaks = []
        for(let i=0;i<width;i++){
            let batch = data.slice(i*step,(i+1)*step)
            let max = Math.max(...batch)
            let min = Math.min(...batch)
            peaks.push([max, min])
        }
        return peaks
    }
    dynamicWaveform(canvas){
        const ctx = canvas.getContext('2d')
        canvas.width = canvas.clientWidth
        canvas.height = canvas.clientHeight
        const analyser = this.analyser
        const data = new Uint8Array(this.analyser.frequencyBinCount)
        const audio = this.player.audio
        const getPeaks = this.getPeaks
        const peaks = [], peakWidth = 4, peakFPS = 20
        var peakScrollRate = 10
        loop()
        function loop(){
            window.requestAnimationFrame(loop)
            analyser.getByteTimeDomainData(data)
            let timeIndex = Math.floor(audio.currentTime*peakFPS)*peakWidth
            getPeaks(Math.ceil(peakWidth*audio.playbackRate), data).map((peak,i)=>{
                peaks[timeIndex+i] = peak
            })
            ctx.clearRect(0,0,canvas.width,canvas.height)
            ctx.beginPath()
            let moved = false
            for(let x=0;x<=canvas.width;x++){
                let i = timeIndex+Math.floor((x-canvas.width+1)*peakWidth/peakScrollRate)
                if(peaks[i]){
                    let y0 = canvas.height*peaks[i][0]/256
                    let y1 = canvas.height*peaks[i][1]/256
                    if(moved){
                        ctx.lineTo(x,y0)
                    }else{
                        ctx.moveTo(x,y0)
                        moved = true
                    }
                    ctx.lineTo(x,y1)
                }else{
                    moved = false
                }
            }
            ctx.stroke()
            ctx.closePath()
        }
    }
    staticWaveform(canvas, peaks, offset=0, color='black'){
        const ctx = canvas.getContext('2d')
        const cy = canvas.height/2
        const max = Math.max(...peaks.map(peak=>Math.max(peak[0],-peak[1])))
        ctx.beginPath()
        ctx.moveTo(offset,cy)
        peaks.map((peak,i)=>{
            ctx.lineTo(offset+i,peak[0]*cy+cy)
            ctx.lineTo(offset+i,peak[1]*cy+cy)
        })
        ctx.strokeStyle = color
        ctx.lineWidth = 1
        ctx.stroke()
        ctx.closePath()
    }
    waveformEditor(canvas, channelData){
        const ctx = canvas.getContext('2d')
        canvas.width = canvas.clientWidth
        canvas.height = canvas.clientHeight
        const cy = canvas.height/2
        const peaks = this.getPeaks(canvas.width, channelData)
        this.staticWaveform(canvas, peaks)
        const bound = {active:false,left:0,right:0,start:0}
        function drawBound(x,type, color='grey'){
            ctx.beginPath()
            ctx.moveTo(x,0)
            ctx.lineTo(x,canvas.height)
            ctx.fillStyle = color
            ctx.strokeStyle = color
            ctx.stroke()
            ctx.fill()
            ctx.closePath()
            ctx.fillRect(type=='left'?x-10:x,cy-15,10,30)
        }
        canvas.addEventListener('contextmenu',e=>{
            e.preventDefault()
        })
        canvas.addEventListener('mousedown',e=>{
            var LEFT=1,MID=2,RIGHT=3
            if(e.which==RIGHT){
                bound.active = true
                bound.start = bound.left = bound.right = Math.floor(e.clientX-canvas.offsetLeft)
                ctx.clearRect(0,0,canvas.width,canvas.height)
                this.staticWaveform(canvas, peaks)
            }
        })
        canvas.addEventListener('mousemove',e=>{
            if(bound.active){
                const left = Math.floor(e.clientX-canvas.offsetLeft)
                ctx.clearRect(0,0,canvas.width,canvas.height)
                this.staticWaveform(canvas, peaks)
                if(left>bound.start){
                    bound.left = bound.start
                    bound.right = left
                }else{
                    bound.left = left
                    bound.right = bound.start
                }
                drawBound(bound.left,'left')
                drawBound(bound.right,'right')
                this.staticWaveform(canvas, peaks.slice(bound.left, bound.right), bound.left, 'dodgerblue')
            }
        })
        canvas.addEventListener('mouseup',e=>{
            bound.active = false
        })
        canvas.addEventListener('mouseleave',e=>{
            bound.active = false
        })
    }
    oscilloscope(canvas){
        const ctx = canvas.getContext('2d')
        this.analyser.fftSize = 2048
        const data = new Uint8Array(this.analyser.frequencyBinCount);
        loop()
        function loop(){
            window.requestAnimationFrame(loop);
            this.analyser.getByteTimeDomainData(data)
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            ctx.lineWidth = 2
            ctx.strokeStyle = 'white'
            ctx.beginPath()
            for(var i=0;i<this.analyser.frequencyBinCount;i++){
                var x = i / this.analyser.frequencyBinCount * canvas.width
                var y = data[i] / 256 * canvas.height
                if(i==0){
                    ctx.moveTo(x,y)
                }else{
                    ctx.lineTo(x,y)
                }
            }
            ctx.lineTo(canvas.width,canvas.height/2)
            ctx.stroke()
            ctx.closePath()
        }
    }
    spectrogram(canvas) { // by Jake Albaugh
        const ctx = canvas.getContext('2d')
        const data = new Uint8Array(this.analyser.frequencyBinCount);
        const h = canvas.height / data.length;
        const x = canvas.width - 1;
        ctx.fillStyle = 'hsl(280, 100%, 10%)';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        loop();
        function loop() {
            window.requestAnimationFrame(loop);
            let imgData = ctx.getImageData(1, 0, canvas.width - 1, canvas.height);
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            ctx.putImageData(imgData, 0, 0);
            this.analyser.getByteFrequencyData(data);
            for (let i = 0; i < data.length; i++) {
                let rat = data[i] / 255;
                let hue = Math.round((rat * 120) + 280 % 360);
                let sat = '100%';
                let lit = 10 + (70 * rat) + '%';
                ctx.beginPath();
                ctx.strokeStyle = `hsl(${hue}, ${sat}, ${lit})`;
                ctx.moveTo(x, canvas.height - (i * h));
                ctx.lineTo(x, canvas.height - (i * h + h));
                ctx.stroke();
            }
        }
    }
}
class AudioPlayer{
    constructor(){
        this.audio = new Audio()
        this.audio.ontimeupdate = e=>{e.target.dispatchEvent(new CustomEvent('time-update'))}
        this.aCtx = new (window.AudioContext || window.webkitAudioContext)()
        this.source = this.aCtx.createMediaElementSource(this.audio)
        this.audioBuffer = null
        this.gain = this.aCtx.createGain()
        this.gain.connect(this.aCtx.destination)
    }
    play(){this.audio.play()}
    pause(){this.audio.pause()}
    get paused(){return this.audio.paused}
    set playbackRate(v){this.audio.playbackRate=v}
    get playbackRate(){return this.audio.playbackRate}
    set currentTime(v){this.audio.currentTime=v}
    get currentTime(){return this.audio.currentTime}
    rewind(offset){
        var t = this.audio.currentTime+offset
        var duration = this.audio.duration
        this.audio.currentTime = t<0?0:t>duration?duration:t
    }
    readAsAudioElementSrc(file){
        this.audio.src = URL.createObjectURL(file)
        return new Promise((resolve,reject)=>{
            this.audio.onloadeddata = resolve
        })
    }
    readAsArrayBuffer(file){
        const reader = new FileReader()
        reader.readAsArrayBuffer(file)
        this.audio.src = URL.createObjectURL(file)
        return new Promise((resolve,reject)=>{
            reader.onload = ()=>{
                this.aCtx.decodeAudioData(reader.result).then(audioBuffer=>{
                    this.audioBuffer = audioBuffer
                    resolve(this.audioBuffer)
                })
            }
        })
    }
}
function handleDrop(e){
    e.preventDefault()
    var files = []
    for(let i=0;i<e.dataTransfer.items.length;i++){
        let item = e.dataTransfer.items[i]
        if(item.kind=='file'){
            files.push(item.getAsFile())
        }
    }
}
var player
async function handleFile(file){
    if(file.type.includes('audio')){
        player = new AudioPlayer()
        var audioBuffer = await player.readAsArrayBuffer(file)
        // await player.readAsAudioElementSrc(file)
        var visualizer = new Visualizer(player)
        var channelData = audioBuffer.getChannelData(0)
        visualizer.waveformEditor(document.getElementById('canvas'), channelData)
        visualizer.dynamicWaveform(document.getElementById('waveform'))
        visualizer.createController(document.getElementById('audio-control'))
    }
}

class Encoder{
    constructor(){

    }
    encodeWAV(audioBuffer, smapleRate){
        const samples = interleave(audioBuffer)
        const buffer = new ArrayBuffer(44 + samples.length * 2)
        const view = new DataView(buffer)

        /* RIFF identifier */
        writeString(view, 0, 'RIFF')
        /* RIFF chunk length */
        view.setUint32(4, 36 + samples.length * 2, true)
        /* RIFF type */
        writeString(view, 8, 'WAVE')
        /* format chunk identifier */
        writeString(view, 12, 'fmt ')
        /* format chunk length */
        view.setUint32(16, 16, true)
        /* sample format (raw) */
        view.setUint16(20, 1, true)
        /* channel count */
        view.setUint16(22, numChannels, true)
        /* sample rate */
        view.setUint32(24, sampleRate, true)
        /* byte rate (sample rate * block align) */
        view.setUint32(28, sampleRate * 4, true)
        /* block align (channel count * bytes per sample) */
        view.setUint16(32, numChannels * 2, true)
        /* bits per sample */
        view.setUint16(34, 16, true)
        /* data chunk identifier */
        writeString(view, 36, 'data')
        /* data chunk length */
        view.setUint32(40, samples.length * 2, true)

        floatTo16BitPCM(view, 44, samples)
        return view

        function interleave(audioBuffer=AudioBuffer) {
            if (audioBuffer.numberOfChannels === 1) {
                return audioBuffer.getChannelData(0)
            } else {
                const L = audioBuffer.getChannelData(0)
                const R = audioBuffer.getChannelData(1)
                let len = L.length+R.length, i = 0, j = 0
                const result = new Float32Array(len)
                while (i<len) {
                    result[i++] = inputL[j]
                    result[i++] = inputR[j]
                    j++
                }
                return result
            }
        }
        function floatTo16BitPCM (view=DataView, offset=Number, input=Float32Array) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                let s = input[i]
                if (s < 0) {
                    if (s < -1) s = -1
                    s *= 0x8000
                } else {
                    if (s > 1) s = 1
                    s *= 0x7FFF
                }
                view.setInt16(offset, s, true)
            }
        }
        function writeString (view=DataView, offset=Number, string=String) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i))
            }
        }
    }
    sliceAudioBuffer(audioBuffer,start=0,end=audioBuffer.length){
        const newBuffer = audioCtx.createBuffer(
            audioBuffer.numberOfChannels,
            end - start,
            audioBuffer.sampleRate
        )
        for(let i=0;i<audioBuffer.numberOfChannels;i++){
            newBuffer.copyToChannel(audioBuffer.getChannelData(i).slice(start,end))
        }
        return newBuffer
    }
    download(blob){
        new Blob([arrayBuffer],{type:'audio/mp3'})
        const url = URL.createObjectURL(blob)
        const link = document.createElement('a')
        link.href = url
        link.download = 'download.mp3'
        document.body.appendChild(link)
        link.click()
        link.remove()
    }
}
</script>
</html>