<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio</title>
</head>
<body>
    <input type="range" id="range" min="0" step="0.1" max="0" value="0">
    <input type="file" onchange="handleFile(event.target.files[0])">
    <div id="drop-field" ondrop="handleDrop(event)" ondragover="event.preventDefault()">drop here</div>
    <canvas id="canvas"></canvas>
</body>
<style>
    html,body{
        margin: 0;
    }
    #canvas{
        width: 500px;
        height: 200px;
    }
    #drop-field{
        width: 50px;
        height: 50px;
        border: 1px solid #000;
    }
</style>
<script>
class Visualizer{
    constructor(audioContext){
        this.audioContext = audioContext||new (window.AudioContext || window.webkitAudioContext)()
        this.analyser = this.audioContext.createAnalyser()
    }
    waveform(){

    }
    oscilloscope(){
        var canvas = document.getElementById('canvas')
        var ctx = canvas.getContext('2d')
        var analyser = this.analyser
        analyser.fftSize = 2048
        const data = new Uint8Array(analyser.frequencyBinCount);
        loop()
        function loop(){
            window.requestAnimationFrame(loop);
            analyser.getByteTimeDomainData(data)
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            ctx.lineWidth = 2
            ctx.strokeStyle = 'white'
            ctx.beginPath()
            for(var i=0;i<analyser.frequencyBinCount;i++){
                var x = i / analyser.frequencyBinCount * canvas.width
                var y = data[i] / 256 * canvas.height
                if(i==0){
                    ctx.moveTo(x,y)
                }else{
                    ctx.lineTo(x,y)
                }
            }
            ctx.lineTo(canvas.width,canvas.height/2)
            ctx.stroke()
            ctx.closePath()
        }
    }
    spectrogram() { // by Jake Albaugh
        var canvas = document.getElementById('canvas')
        var ctx = canvas.getContext('2d')
        var analyser = this.analyser
        const data = new Uint8Array(analyser.frequencyBinCount);
        const h = canvas.height / data.length;
        const x = canvas.width - 1;
        ctx.fillStyle = 'hsl(280, 100%, 10%)';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        loop();
        function loop() {
            window.requestAnimationFrame(loop);
            let imgData = ctx.getImageData(1, 0, canvas.width - 1, canvas.height);
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            ctx.putImageData(imgData, 0, 0);
            analyser.getByteFrequencyData(data);
            for (let i = 0; i < data.length; i++) {
                let rat = data[i] / 255;
                let hue = Math.round((rat * 120) + 280 % 360);
                let sat = '100%';
                let lit = 10 + (70 * rat) + '%';
                ctx.beginPath();
                ctx.strokeStyle = `hsl(${hue}, ${sat}, ${lit})`;
                ctx.moveTo(x, canvas.height - (i * h));
                ctx.lineTo(x, canvas.height - (i * h + h));
                ctx.stroke();
            }
        }
    }
}
class AudioPlayer{
    constructor(){
        this.audio = new Audio()
    }
    rewind(offset){
        var t = this.audio.currentTime+offset
        var duration = this.audio.duration
        this.audio.currentTime = t<0?0:t>duration?duration:t
    }
}
var audio = new Audio()
var range = document.getElementById('range')
function handleDrop(e){
    e.preventDefault()
    var files = []
    for(let i=0;i<e.dataTransfer.items.length;i++){
        let item = e.dataTransfer.items[i]
        if(item.kind=='file'){
            files.push(item.getAsFile())
        }
    }
    const reader = new FileReader()
    reader.readAsDataURL(files[0])
    reader.onload = ()=>{
        audio.src = reader.result
        audio.onloadeddata = ()=>{
            range.max = audio.duration
        }
        audio.ontimeupdate = ()=>{
            range.value = audio.currentTime
        }
        range.oninput = e=>{
            audio.currentTime = e.target.value
            audio.playbackRate = 1
        }
        var visualizer = new Visualizer()
        var mls = visualizer.audioContext.createMediaElementSource(audio)
        mls.connect(visualizer.analyser)
        visualizer.analyser.connect(visualizer.audioContext.destination)
        visualizer.oscilloscope()
        audio.play()
    }
}
async function handleFile(file){
    if(file.type=='audio/mp3'){
        console.log(file.type)
        var decoder = new Decoder()
        var arrayBuffer = await decoder.readFile(file)
        var audioBuffer = await decoder.decode(arrayBuffer)
        console.log(audioBuffer)
        decoder.setSource(audioBuffer)
        decoder.bufferSource.connect(decoder.audioContext.destination)
        decoder.bufferSource.start()
        var data = audioBuffer.getChannelData(0)
        decoder.waveform(data)
        var visualizer = new Visualizer(decoder.audioContext)
        decoder.bufferSource.connect(visualizer.analyser)
        visualizer.spectrogram()
    }
}
class Decoder{
    constructor(){
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)()
        this.bufferSource = this.audioContext.createBufferSource()
    }
    readFile(file){
        return new Promise(resolve=>{
            const reader = new FileReader()
            reader.readAsArrayBuffer(file)
            reader.onload = ()=>{
                resolve(reader.result)
            }
        })
    }
    decode(arrayBuffer){
        return this.audioContext.decodeAudioData(arrayBuffer)
    }
    setSource(audioBuffer){
        this.bufferSource.buffer = audioBuffer
    }
    getPeaks(width, data){
        const step = Math.floor(data.length/width)
        var peaks = new Array(width)
        var minPeak = 0, maxPeak = 0
        for(let i=0;i<width;i++){
            let batch = data.slice(i*step,(i+1)*step)
            let min = Math.min(...batch)
            let max = Math.max(...batch)
            minPeak = Math.min(min, minPeak)
            maxPeak = Math.max(max, maxPeak)
            peaks[i] = [min,max]
        }
        return peaks.map(peak=>([-peak[0]/minPeak, peak[1]/maxPeak]))
    } 
    waveform(data){
        const canvas = document.getElementById('canvas')
        const rect = canvas.getBoundingClientRect()
        canvas.height = rect.height
        canvas.width = rect.width
        const ctx = canvas.getContext('2d')
        var peaks = this.getPeaks(rect.width, data)
        var cy = rect.height/2
        var amp = rect.height/4
        redraw()
        var bound = {active:false,left:0,right:0,start:0}
        canvas.addEventListener('contextmenu',e=>{
            e.preventDefault()
        })
        function redraw(){
            ctx.clearRect(0,0,canvas.width,canvas.height)
            ctx.beginPath()
            ctx.moveTo(0,cy)
            peaks.map((peak,i)=>{
                ctx.lineTo(i,peak[0]*amp+cy)
                ctx.lineTo(i,peak[1]*amp+cy)
            })
            ctx.strokeStyle = 'black'
            ctx.lineWidth = 1
            ctx.stroke()
            ctx.closePath()
        }
        canvas.addEventListener('mousedown',e=>{
            var LEFT=1,MID=2,RIGHT=3
            if(e.which==RIGHT){
                bound.active = true
                bound.start = bound.left = bound.right = Math.floor(e.clientX-rect.left)
                redraw()
            }
        })
        canvas.addEventListener('mousemove',e=>{
            if(bound.active){
                let left = Math.floor(e.clientX-rect.left)
                redraw()
                if(left>bound.start){
                    bound.left = bound.start
                    bound.right = left
                }else{
                    bound.left = left
                    bound.right = bound.start
                }
                ctx.beginPath()
                ctx.moveTo(bound.left,0)
                ctx.lineTo(bound.left,rect.height)
                ctx.fillRect(bound.left-10,cy-15,10,30)
                ctx.fillStyle = 'grey'
                ctx.strokeStyle = 'grey'
                ctx.stroke()
                ctx.fill()
                ctx.closePath()

                ctx.fillRect(bound.right,cy-15,10,30)
                ctx.moveTo(bound.right,0)
                ctx.lineTo(bound.right,rect.height)
                ctx.fillStyle = 'grey'
                ctx.strokeStyle = 'grey'
                ctx.stroke()
                ctx.fill()
                ctx.closePath()

                ctx.beginPath()
                ctx.moveTo(bound.left,cy)
                peaks.slice(bound.left,bound.right).map((peak,i)=>{
                    let x = bound.left+i
                    ctx.lineTo(x,peak[0]*amp+cy)
                    ctx.lineTo(x,peak[1]*amp+cy)
                })
                ctx.strokeStyle = 'dodgerblue'
                ctx.lineWidth = 1
                ctx.stroke()
                ctx.closePath()
            }
        })
        canvas.addEventListener('mouseup',e=>{
            bound.active = false
        })
        canvas.addEventListener('mouseleave',e=>{
            bound.active = false
        })
    }
}

class Encoder{
    constructor(){

    }
    encodeMP3(audioBuffer, smapleRate=44100, kbps=128){
        let mp3encoder = new lamejs.Mp3Encoder(audioBuffer.numberOfChannels, smapleRate, kbps)
        let mp3Data = mp3encoder.encodeBuffer(audioBuffer)
        return new Blob(mp3Data)
    }
    encodeWAV(audioBuffer, smapleRate){
        const samples = interleave(audioBuffer)
        const buffer = new ArrayBuffer(44 + samples.length * 2)
        const view = new DataView(buffer)

        /* RIFF identifier */
        writeString(view, 0, 'RIFF')
        /* RIFF chunk length */
        view.setUint32(4, 36 + samples.length * 2, true)
        /* RIFF type */
        writeString(view, 8, 'WAVE')
        /* format chunk identifier */
        writeString(view, 12, 'fmt ')
        /* format chunk length */
        view.setUint32(16, 16, true)
        /* sample format (raw) */
        view.setUint16(20, 1, true)
        /* channel count */
        view.setUint16(22, numChannels, true)
        /* sample rate */
        view.setUint32(24, sampleRate, true)
        /* byte rate (sample rate * block align) */
        view.setUint32(28, sampleRate * 4, true)
        /* block align (channel count * bytes per sample) */
        view.setUint16(32, numChannels * 2, true)
        /* bits per sample */
        view.setUint16(34, 16, true)
        /* data chunk identifier */
        writeString(view, 36, 'data')
        /* data chunk length */
        view.setUint32(40, samples.length * 2, true)

        floatTo16BitPCM(view, 44, samples)
        return view

        function interleave(audioBuffer=AudioBuffer) {
            if (audioBuffer.numberOfChannels === 1) {
                return audioBuffer.getChannelData(0)
            } else {
                const L = audioBuffer.getChannelData(0)
                const R = audioBuffer.getChannelData(1)
                let len = L.length+R.length, i = 0, j = 0
                const result = new Float32Array(len)
                while (i<len) {
                    result[i++] = inputL[j]
                    result[i++] = inputR[j]
                    j++
                }
                return result
            }
        }
        function floatTo16BitPCM (view=DataView, offset=Number, input=Float32Array) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                let s = input[i]
                if (s < 0) {
                    if (s < -1) s = -1
                    s *= 0x8000
                } else {
                    if (s > 1) s = 1
                    s *= 0x7FFF
                }
                view.setInt16(offset, s, true)
            }
        }
        function writeString (view=DataView, offset=Number, string=String) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i))
            }
        }
    }
    sliceAudioBuffer(audioBuffer,start=0,end=audioBuffer.length){
        const newBuffer = audioCtx.createBuffer(
            audioBuffer.numberOfChannels,
            end - start,
            audioBuffer.sampleRate
        )
        for(let i=0;i<audioBuffer.numberOfChannels;i++){
            newBuffer.copyToChannel(audioBuffer.getChannelData(i).slice(start,end))
        }
        return newBuffer
    }
    download(blob){
        new Blob([arrayBuffer],{type:'audio/mp3'})
        const url = URL.createObjectURL(blob)
        const link = document.createElement('a')
        link.href = url
        link.download = 'download.mp3'
        document.body.appendChild(link)
        link.click()
        link.remove()
    }
}
</script>
</html>